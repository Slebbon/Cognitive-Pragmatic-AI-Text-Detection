{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2BdxsPEiy-Z",
        "outputId": "25d8b130-cbb5-43b8-9894-24c6f3d239f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MASTER FEATURES - TRAIN/TEST SPLIT INITIALIZATION\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Master features: /content/drive/MyDrive/Tesi Magistrale/master_features/master_features_complete_2.csv\n",
            "Commercial test: /content/Testing-Commercial.csv\n",
            "Output directory: /content/drive/MyDrive/Tesi Magistrale/train_test_splits\n"
          ]
        }
      ],
      "source": [
        "#Master Features - Train/Test Split with Commercial Overlap\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "print(\"MASTER FEATURES - TRAIN/TEST SPLIT INITIALIZATION\")\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base paths\n",
        "BASE_DRIVE = '/content/drive/MyDrive/Tesi Magistrale'\n",
        "MASTER_DIR = f'{BASE_DRIVE}/master_features'\n",
        "\n",
        "# File paths\n",
        "MASTER_FEATURES_PATH = f'{MASTER_DIR}/master_features_complete_2.csv'\n",
        "COMMERCIAL_TEST_PATH = '/content/Testing-Commercial.csv'  # Adjust if needed\n",
        "\n",
        "# Output directory for splits\n",
        "SPLITS_DIR = f'{BASE_DRIVE}/train_test_splits'\n",
        "os.makedirs(SPLITS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Master features: {MASTER_FEATURES_PATH}\")\n",
        "print(f\"Commercial test: {COMMERCIAL_TEST_PATH}\")\n",
        "print(f\"Output directory: {SPLITS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature categories dictionary\n",
        "FEATURE_CATEGORIES = {\n",
        "    'BACKBONE': [\n",
        "        'alpha_ratio', 'punct_ratio', 'avg_word_length', 'std_word_length',\n",
        "        'entropy_bits', 'entropy_norm', 'type_token_ratio', 'stopword_ratio',\n",
        "        'avg_sentence_length', 'sentence_length_std', 'n_sentences_doc',\n",
        "        'flesch_reading_ease', 'trigram_diversity', 'token_burstiness',\n",
        "        'char_trigram_entropy', 'uppercase_ratio', 'unique_char_count',\n",
        "        'compression_ratio', 'avg_tree_depth', 'max_tree_depth',\n",
        "        'avg_dependency_distance', 'left_dependency_ratio', 'hapax_legomena_ratio',\n",
        "        'yules_k', 'comma_ratio', 'period_ratio', 'question_ratio',\n",
        "        'exclamation_ratio', 'semicolon_ratio', 'colon_ratio', 'quote_ratio',\n",
        "        'sentiment_polarity', 'sentiment_subjectivity', 'sentiment_polarity_variance',\n",
        "        'neutral_sentence_ratio', 'positive_word_ratio', 'negative_word_ratio',\n",
        "        'pos_ratio_DET', 'pos_ratio_ADP', 'pos_ratio_AUX', 'pos_ratio_CCONJ',\n",
        "        'pos_ratio_PART', 'pos_ratio_NUM', 'pos_row_entropy_weighted',\n",
        "        'function_to_content_rate', 'noun_verb_alternation_rate',\n",
        "        'content_function_ratio', 'noun_verb_ratio', 'adj_adv_ratio',\n",
        "        'verbs_per_100_tok', 'nouns_per_100_tok', 'adj_per_100_tok',\n",
        "        'adv_per_100_tok', 'pron_per_100_tok', 'punct_per_100_tok',\n",
        "        'tokens_per_sentence_mean', 'mean_nouns_per_sent', 'mean_verbs_per_sent',\n",
        "        'mean_adjs_per_sent', 'mean_advs_per_sent', 'prop_sents_with_verb',\n",
        "        'unique_upos_per_sent_mean', 'max_runlen_NOUN', 'max_runlen_PUNCT',\n",
        "    ],\n",
        "    'COREFERENCE': [\n",
        "        'pronoun_ratio', 'minimal_chain_ratio', 'avg_chain_length',\n",
        "        'chain_length_variance', 'long_range_coref_ratio', 'chain_connectivity',\n",
        "        'repeat_mention_expansion_rate', 'avg_tokens_added_on_repeat',\n",
        "        'repeat_overspecification_ratio', 'adjective_modification_rate',\n",
        "        'prepositional_modification_rate', 'relative_clause_rate',\n",
        "        'modification_type_entropy', 'avg_modifiers_per_mention',\n",
        "        'second_mention_pronoun_rate', 'full_np_in_repeats_rate',\n",
        "        'macro_avg_context_entities', 'meso_pragmatic_necessity_rate',\n",
        "        'macro_overspecification_loose_rate', 'meso_consensus_score_mean',\n",
        "        'micro_statistical_typicality_mean', 'macro_modification_vs_competitors_ratio',\n",
        "        'meso_context_density', 'scale_consistency_score',\n",
        "        'micro_meso_overspec_gradient', 'meso_macro_context_ratio',\n",
        "        'necessity_scale_variance', 'minimal_chain_count',\n",
        "        'minimal_first_avg_modifiers', 'minimal_second_pronoun_rate',\n",
        "        'minimal_avg_total_modifiers', 'singleton_count', 'singleton_ratio',\n",
        "        'singleton_avg_modifiers', 'singleton_descriptive_rate',\n",
        "        'singleton_vs_chain_first_ratio', 'singleton_modification_entropy',\n",
        "        'singleton_avg_tokens',\n",
        "    ],\n",
        "    'PERPLEXITY': [\n",
        "        'doc_perplexity', 'mean_sentence_perplexity', 'sentence_perplexity_variance',\n",
        "        'token_probability_entropy', 'perplexity_curvature', 'perplexity_burstiness',\n",
        "        'perplexity_trajectory_slope', 'perturbation_discrepancy',\n",
        "    ],\n",
        "    'COHESION': [\n",
        "        'entity_mention_density', 'entity_reuse_rate', 'entity_graph_density',\n",
        "        'entity_isolated_sentences', 'entity_largest_component_size',\n",
        "        'mean_entity_continuation_rate', 'mean_adjacent_cosine_similarity',\n",
        "        'min_adjacent_cosine_similarity', 'adjacent_similarity_variance',\n",
        "        'semantic_graph_density', 'similarity_decay_rate',\n",
        "        'mean_nonadjacent_similarity', 'long_range_similarity',\n",
        "        'semantic_graph_isolated_sentences', 'semantic_largest_component_size',\n",
        "        'semantic_average_degree', 'topic_entropy', 'topic_drift_rate',\n",
        "        'dominant_topic_proportion', 'topic_switching_frequency',\n",
        "        'topic_persistence', 'num_distinct_topics', 'topic_diversity',\n",
        "        'topic_concentration', 'topic_transition_similarity', 'topic_return_rate',\n",
        "    ],\n",
        "    'TEMPORAL': [\n",
        "        'temp_num_events', 'temp_events_per_sentence', 'temp_event_lexical_diversity',\n",
        "        'temp_tense_distribution_entropy', 'temp_num_timex', 'temp_timex_event_ratio',\n",
        "        'temp_rel_mean_confidence', 'temp_rel_confidence_variance',\n",
        "        'temp_rel_before_after_ratio', 'temp_rel_cycle_edge_ratio',\n",
        "        'temp_rel_raw_cycle_count', 'temp_rel_cycle_approx_flag',\n",
        "        'temp_rel_parallel_edge_rate', 'temp_rel_type_entropy',\n",
        "        'temp_rel_transitivity_violation_rate', 'tg_edge_retention',\n",
        "        'tg_degree_entropy', 'tg_avg_in_degree', 'tg_avg_out_degree',\n",
        "        'tg_ordering_entropy', 'tg_longest_path', 'tg_mean_depth',\n",
        "        'tg_branching_factor', 'tg_global_coherence',\n",
        "        'temp_constraint_violation_rate', 'temp_constraint_csp_score',\n",
        "        'temp_scope_variance', 'temp_tense_time_alignment',\n",
        "        'temp_deixis_consistency', 'temp_ref_time_shifts',\n",
        "        'tg_centralization', 'tg_clustering_coefficient', 'tg_density',\n",
        "    ],\n",
        "    'METACOGNITION': [\n",
        "        'transitions_density', 'frame_markers_density', 'endophoric_markers_density',\n",
        "        'attitude_markers_density', 'engagement_markers_density', 'hedges_density',\n",
        "        'boosters_density', 'epistemic_density', 'personal_epistemic_density',\n",
        "        'reformulation_density', 'self_mention_first_use_ratio',\n",
        "        'self_mention_first_20pct_density', 'certainty_first_third',\n",
        "        'certainty_last_third', 'certainty_gradient', 'certainty_overall',\n",
        "        'weasel_density', 'evidential_density',\n",
        "    ],\n",
        "    'CALIBRATION': [\n",
        "        'hedge_perplexity_correlation', 'booster_perplexity_anticorrelation',\n",
        "        'metacog_spike_perplexity_ratio', 'certainty_perplexity_alignment',\n",
        "        'reformulation_complexity_match',\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "print(f\"Feature categories defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVzqCpTykNnp",
        "outputId": "5bd6eff3-fe2c-44b9-dc26-85712984ce53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature categories defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Loading master features from: {MASTER_FEATURES_PATH}\")\n",
        "\n",
        "try:\n",
        "    df_master = pd.read_csv(MASTER_FEATURES_PATH)\n",
        "    print(f\"Master features loaded successfully\")\n",
        "\n",
        "    # Verify essential columns\n",
        "    if 'id' not in df_master.columns:\n",
        "        raise ValueError(\"Missing 'id' column in master features!\")\n",
        "    if 'is_ai' not in df_master.columns:\n",
        "        raise ValueError(\"Missing 'is_ai' column in master features!\")\n",
        "\n",
        "\n",
        "    # Verify features are present\n",
        "    feature_cols = [col for col in df_master.columns if col not in ['id', 'is_ai']]\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Master features file not found!\")\n",
        "    print(f\"Path: {MASTER_FEATURES_PATH}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"ERROR loading master features: {e}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uDEAkZ2kWQZ",
        "outputId": "08edc7c6-8136-4b6e-db68-e040376d994b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading master features from: /content/drive/MyDrive/Tesi Magistrale/master_features/master_features_complete_2.csv\n",
            "Master features loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load commercial\n",
        "\n",
        "print(f\"Loading commercial test set from: {COMMERCIAL_TEST_PATH}\")\n",
        "\n",
        "try:\n",
        "    df_commercial = pd.read_csv(COMMERCIAL_TEST_PATH)\n",
        "    print(f\"Commercial test set loaded successfully\")\n",
        "    print(f\"Columns: {list(df_commercial.columns)}\")\n",
        "\n",
        "    # Check for ID column\n",
        "    id_col_commercial = None\n",
        "    for possible_id in ['id', 'uuid', 'ID', 'UUID']:\n",
        "        if possible_id in df_commercial.columns:\n",
        "            id_col_commercial = possible_id\n",
        "\n",
        "    print(f\"Using ID column: '{id_col_commercial}'\")\n",
        "\n",
        "    # Check for label column\n",
        "    label_col_commercial = None\n",
        "    for possible_label in ['is_ai', 'label', 'Label', 'is_AI']:\n",
        "        if possible_label in df_commercial.columns:\n",
        "            label_col_commercial = possible_label\n",
        "            break\n",
        "\n",
        "    if label_col_commercial:\n",
        "        print(f\"Label column found: '{label_col_commercial}\")\n",
        "        n_ai_comm = (df_commercial[label_col_commercial] == 1).sum()\n",
        "        n_human_comm = (df_commercial[label_col_commercial] == 0).sum()\n",
        "    else:\n",
        "        print(f\"No label column found\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Commercial test file not found!\")\n",
        "    print(f\"Path: {COMMERCIAL_TEST_PATH}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"ERROR loading commercial test set: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQgXRuORkYz5",
        "outputId": "6b857c9e-1bc3-437f-968e-6cc32d66c4c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading commercial test set from: /content/Testing-Commercial.csv\n",
            "Commercial test set loaded successfully\n",
            "Columns: ['id', 'generation', 'label', 'GPTZero', 'Quillboat', 'Sapling', 'WalterAI', 'ZeroGPT']\n",
            "  • Using ID column: 'id'\n",
            "Label column found: 'label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Overlapping ids\n",
        "\n",
        "# Get ID sets\n",
        "master_ids = set(df_master['id'].values)\n",
        "commercial_ids = set(df_commercial[id_col_commercial].values)\n",
        "\n",
        "# Find overlap\n",
        "overlapping_ids = master_ids & commercial_ids\n",
        "\n",
        "# Show overlap percentage\n",
        "overlap_pct_commercial = (len(overlapping_ids) / len(commercial_ids)) * 100\n",
        "\n",
        "print(f\"Overlap statistics:\")\n",
        "print(f\"% of commercial dataset: {overlap_pct_commercial:.2f}%\")\n",
        "\n",
        "# Show sample overlapping IDs\n",
        "print(f\"\\n  Sample overlapping IDs:\")\n",
        "for i, id_val in enumerate(list(overlapping_ids)[:5], 1):\n",
        "    print(f\"    {i}. {id_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdiWJ3NOkdIf",
        "outputId": "a3c8939e-fa75-4bcc-b649-02b576707045"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap statistics:\n",
            "% of commercial dataset: 100.00%\n",
            "\n",
            "  Sample overlapping IDs:\n",
            "    1. 4a84a694-1ad6-498f-8ac4-1938b8b067cd\n",
            "    2. 9ac40e82-3385-4090-866c-fa04bdffd475\n",
            "    3. 3216fd24-4854-443d-8b65-582d157e5821\n",
            "    4. 8dcb2914-d011-48fd-be29-feb8482e5b55\n",
            "    5. 9a0e73ff-4f4c-4439-bb5a-d00e104633ad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Train/Test Split\n",
        "\n",
        "# Split based on overlapping IDs\n",
        "df_test = df_master[df_master['id'].isin(overlapping_ids)].copy()\n",
        "df_train = df_master[~df_master['id'].isin(overlapping_ids)].copy()\n",
        "\n",
        "# Verify no overlap\n",
        "assert len(set(df_train['id']) & set(df_test['id'])) == 0, \"Train/test overlap detected!\"\n",
        "print(f\"No ID overlap between train and test sets\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBG6TFxUkfQm",
        "outputId": "3e504f3b-f2b0-46e5-f66a-525ffe313e6f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No ID overlap between train and test sets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Matrices\n",
        "\n",
        "#Get feature columns (exclude id and label)\n",
        "feature_cols = [col for col in df_master.columns if col not in ['id', 'is_ai']]\n",
        "\n",
        "print(f\"Extracting features:\")\n",
        "\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = df_train[feature_cols].copy()\n",
        "y_train = df_train['is_ai'].copy()\n",
        "ids_train = df_train['id'].copy()\n",
        "\n",
        "X_test = df_test[feature_cols].copy()\n",
        "y_test = df_test['is_ai'].copy()\n",
        "ids_test = df_test['id'].copy()\n",
        "\n",
        "print(f\"Feature matrices created\")\n",
        "\n",
        "# Check for any data quality issues\n",
        "print(f\"Data quality check:\")\n",
        "\n",
        "# NaN values\n",
        "train_nans = X_train.isna().sum().sum()\n",
        "test_nans = X_test.isna().sum().sum()\n",
        "print(f\"NaN values in train: {train_nans}\")\n",
        "print(f\"NaN values in test: {test_nans}\")\n",
        "\n",
        "if train_nans > 0 or test_nans > 0:\n",
        "    print(f\"    ⚠ WARNING: NaN values detected!\")\n",
        "\n",
        "# Infinite values\n",
        "train_infs = np.isinf(X_train).sum().sum()\n",
        "test_infs = np.isinf(X_test).sum().sum()\n",
        "print(f\"Infinite values in train: {train_infs}\")\n",
        "print(f\"Infinite values in test: {test_infs}\")\n",
        "\n",
        "if train_infs > 0 or test_infs > 0:\n",
        "    print(f\"Infinite values detected!\")\n",
        "\n",
        "if train_nans == 0 and test_nans == 0 and train_infs == 0 and test_infs == 0:\n",
        "    print(f\"No data quality issues detected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxjJDJnLkhcQ",
        "outputId": "4bcc1638-6ec9-4edb-fdbc-d75da21270c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features:\n",
            "Feature matrices created\n",
            "Data quality check:\n",
            "NaN values in train: 0\n",
            "NaN values in test: 0\n",
            "Infinite values in train: 0\n",
            "Infinite values in test: 0\n",
            "No data quality issues detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train model\n",
        "\n",
        "# Import necessary libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "\n",
        "# XGBoost hyperparameters\n",
        "xgb_params = {\n",
        "    'n_estimators': 500,\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.15,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'min_child_weight': 3,\n",
        "    'gamma': 0.1,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 1.0,\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'tree_method': 'hist',  # Faster on CPU\n",
        "}\n",
        "\n",
        "print(f\"XGBoost configuration\")\n",
        "for param, value in xgb_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# Train the model\n",
        "print(f\"Training model\")\n",
        "model = xgb.XGBClassifier(**xgb_params)\n",
        "\n",
        "# Fit with evaluation set to track performance\n",
        "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    eval_set=eval_set,\n",
        "    verbose=50  # Print every 50 rounds\n",
        ")\n",
        "\n",
        "print(f\"Model training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9fwiWvRlPYZ",
        "outputId": "285ba7fe-9223-4fe8-9797-7c46f4602b5d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost configuration\n",
            "  • n_estimators: 500\n",
            "  • max_depth: 9\n",
            "  • learning_rate: 0.15\n",
            "  • subsample: 0.8\n",
            "  • colsample_bytree: 0.8\n",
            "  • min_child_weight: 3\n",
            "  • gamma: 0.1\n",
            "  • reg_alpha: 0.1\n",
            "  • reg_lambda: 1.0\n",
            "  • objective: binary:logistic\n",
            "  • eval_metric: logloss\n",
            "  • random_state: 42\n",
            "  • n_jobs: -1\n",
            "  • tree_method: hist\n",
            "Training model\n",
            "[0]\tvalidation_0-logloss:0.60612\tvalidation_1-logloss:0.61401\n",
            "[50]\tvalidation_0-logloss:0.06382\tvalidation_1-logloss:0.14135\n",
            "[100]\tvalidation_0-logloss:0.02623\tvalidation_1-logloss:0.10930\n",
            "[150]\tvalidation_0-logloss:0.01513\tvalidation_1-logloss:0.10244\n",
            "[200]\tvalidation_0-logloss:0.01052\tvalidation_1-logloss:0.10097\n",
            "[250]\tvalidation_0-logloss:0.00815\tvalidation_1-logloss:0.10011\n",
            "[300]\tvalidation_0-logloss:0.00675\tvalidation_1-logloss:0.09308\n",
            "[350]\tvalidation_0-logloss:0.00619\tvalidation_1-logloss:0.09316\n",
            "[400]\tvalidation_0-logloss:0.00584\tvalidation_1-logloss:0.09479\n",
            "[450]\tvalidation_0-logloss:0.00567\tvalidation_1-logloss:0.09037\n",
            "[499]\tvalidation_0-logloss:0.00562\tvalidation_1-logloss:0.09147\n",
            "Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Perfomance\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"Predictions generated\")\n",
        "\n",
        "\n",
        "# TRAINING SET PERFORMANCE\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_precision = precision_score(y_train, y_train_pred)\n",
        "train_recall = recall_score(y_train, y_train_pred)\n",
        "train_f1 = f1_score(y_train, y_train_pred)\n",
        "train_auc = roc_auc_score(y_train, y_train_proba)\n",
        "\n",
        "print(f\"Metrics:\")\n",
        "print(f\"Accuracy:  {train_accuracy:.4f}\")\n",
        "print(f\"Precision: {train_precision:.4f}\")\n",
        "print(f\"Recall:    {train_recall:.4f}\")\n",
        "print(f\"F1 Score:  {train_f1:.4f}\")\n",
        "print(f\"ROC AUC:   {train_auc:.4f}\")\n",
        "\n",
        "\n",
        "# TEST SET PERFORMANCE (COMMERCIAL HOLDOUT)\n",
        "\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, y_test_proba)\n",
        "\n",
        "print(f\"\\nMetrics:\")\n",
        "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall:    {test_recall:.4f}\")\n",
        "print(f\"F1 Score:  {test_f1:.4f}\")\n",
        "print(f\"ROC AUC:   {test_auc:.4f}\")\n",
        "\n",
        "# PERFORMANCE COMPARISON\n",
        "\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"Train vs Test\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'],\n",
        "    'Train': [train_accuracy, train_precision, train_recall, train_f1, train_auc],\n",
        "    'Test': [test_accuracy, test_precision, test_recall, test_f1, test_auc],\n",
        "})\n",
        "comparison_df['Difference'] = comparison_df['Train'] - comparison_df['Test']\n",
        "\n",
        "print(f\"\\n{comparison_df.to_string(index=False)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1P9A4DlUki",
        "outputId": "1eef0ba4-4a2e-43cf-f055-fce7b4bff7cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions generated\n",
            "Metrics:\n",
            "Accuracy:  1.0000\n",
            "Precision: 1.0000\n",
            "Recall:    1.0000\n",
            "F1 Score:  1.0000\n",
            "ROC AUC:   1.0000\n",
            "\n",
            "Metrics:\n",
            "Accuracy:  0.9600\n",
            "Precision: 1.0000\n",
            "Recall:    0.9167\n",
            "F1 Score:  0.9565\n",
            "ROC AUC:   0.9968\n",
            "\n",
            "================================================================================\n",
            "Train vs Test\n",
            "================================================================================\n",
            "\n",
            "   Metric  Train     Test  Difference\n",
            " Accuracy    1.0 0.960000    0.040000\n",
            "Precision    1.0 1.000000    0.000000\n",
            "   Recall    1.0 0.916667    0.083333\n",
            " F1 Score    1.0 0.956522    0.043478\n",
            "  ROC AUC    1.0 0.996795    0.003205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Importance Analysis\n",
        "\n",
        "print(\"Feature Importance Analysis\")\n",
        "\n",
        "# Get feature importances\n",
        "feature_importance = model.feature_importances_\n",
        "\n",
        "# Get feature names from the columns (excluding id and label)\n",
        "feature_names = [col for col in df_master.columns if col not in ['id', 'is_ai']]\n",
        "\n",
        "\n",
        "# Create dataframe\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# Add category information\n",
        "def get_feature_category(feature_name):\n",
        "    for category, features in FEATURE_CATEGORIES.items():\n",
        "        if feature_name in features:\n",
        "            return category\n",
        "    return 'UNKNOWN'\n",
        "\n",
        "importance_df['category'] = importance_df['feature'].apply(get_feature_category)\n",
        "\n",
        "print(f\"\\n→ Top 20 Most Important Features:\")\n",
        "print(f\"\\n{'Rank':<6}{'Feature':<40}{'Category':<20}{'Importance':<12}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx, row in importance_df.head(20).iterrows():\n",
        "    rank = importance_df.index.get_loc(idx) + 1\n",
        "    print(f\"{rank:<6}{row['feature']:<40}{row['category']:<20}{row['importance']:.6f}\")\n",
        "\n",
        "# Importance by category\n",
        "print(f\"Feature Importance by Category:\")\n",
        "category_importance = importance_df.groupby('category')['importance'].agg(['sum', 'mean'])\n",
        "category_importance = category_importance.sort_values('sum', ascending=False)\n",
        "category_importance.columns = ['Total', 'Average']\n",
        "\n",
        "print(f\"\\n{category_importance.to_string()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeXo8DBOmOHp",
        "outputId": "a0d4b881-a67e-4796-b4f0-bfd5d7545d6e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Analysis\n",
            "\n",
            "→ Top 20 Most Important Features:\n",
            "\n",
            "Rank  Feature                                 Category            Importance  \n",
            "================================================================================\n",
            "1     type_token_ratio                        BACKBONE            0.042063\n",
            "2     doc_perplexity                          PERPLEXITY          0.036596\n",
            "3     tg_ordering_entropy                     TEMPORAL            0.034156\n",
            "4     mean_sentence_perplexity                PERPLEXITY          0.027468\n",
            "5     temp_scope_variance                     TEMPORAL            0.021233\n",
            "6     yules_k                                 BACKBONE            0.019114\n",
            "7     pos_row_entropy_weighted                BACKBONE            0.018425\n",
            "8     comma_ratio                             BACKBONE            0.016069\n",
            "9     pos_ratio_NUM                           BACKBONE            0.014350\n",
            "10    sentence_length_std                     BACKBONE            0.012889\n",
            "11    tg_longest_path                         TEMPORAL            0.012879\n",
            "12    semantic_average_degree                 COHESION            0.012810\n",
            "13    topic_entropy                           COHESION            0.012649\n",
            "14    content_function_ratio                  BACKBONE            0.012354\n",
            "15    tg_density                              TEMPORAL            0.011142\n",
            "16    exclamation_ratio                       BACKBONE            0.010909\n",
            "17    hapax_legomena_ratio                    BACKBONE            0.010628\n",
            "18    prop_sents_with_verb                    BACKBONE            0.010288\n",
            "19    char_trigram_entropy                    BACKBONE            0.009711\n",
            "20    max_runlen_NOUN                         BACKBONE            0.009229\n",
            "Feature Importance by Category:\n",
            "\n",
            "                  Total   Average\n",
            "category                         \n",
            "BACKBONE       0.428645  0.006698\n",
            "TEMPORAL       0.188393  0.005709\n",
            "COREFERENCE    0.118483  0.003118\n",
            "COHESION       0.105027  0.004040\n",
            "PERPLEXITY     0.088285  0.011036\n",
            "METACOGNITION  0.056808  0.003156\n",
            "CALIBRATION    0.014358  0.002872\n"
          ]
        }
      ]
    }
  ]
}